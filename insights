pip install azure-storage-blob langchain openai requests



import os
import json
import requests
import pandas as pd
from io import BytesIO
from datetime import datetime, timedelta
from azure.storage.blob import (
    BlobServiceClient,
    generate_blob_sas,
    BlobSasPermissions
)
from langchain.document_loaders.csv_loader import CSVLoader
from langchain.chat_models import ChatOpenAI
from langchain.chains.question_answering import load_qa_chain

# -----------------------
# Your existing config
# -----------------------
AZURE_CONFIG = {
    "conn_str": "<your-azure-blob-connection-string>",
    "container": "<your-container-name>",
    "results_folder": "<your-folder-inside-container>"
}

OPENAI_CONFIG = {
    "api_key": "<your-azure-openai-key>",
    "endpoint": "<your-endpoint>",  # e.g., https://<resource-name>.openai.azure.com
    "api_version": "<your-api-version>",  # e.g., "2024-03-01-preview"
    "deployment": "<your-deployment-name>"  # e.g., "gpt-4o-mini"
}

# -----------------------
# Generate SAS URL for latest result CSV
# -----------------------
def generate_latest_blob_sas_url():
    blob_service = BlobServiceClient.from_connection_string(AZURE_CONFIG["conn_str"])
    container = blob_service.get_container_client(AZURE_CONFIG["container"])
    blobs = sorted(
        container.list_blobs(name_starts_with=f"{AZURE_CONFIG['results_folder']}/"),
        key=lambda b: b.creation_time,
        reverse=True
    )
    if not blobs:
        print("‚ùå No result blobs found.")
        return None

    latest_blob = blobs[0]
    sas_token = generate_blob_sas(
        account_name=blob_service.account_name,
        container_name=AZURE_CONFIG["container"],
        blob_name=latest_blob.name,
        account_key=blob_service.credential.account_key,
        permission=BlobSasPermissions(read=True),
        expiry=datetime.utcnow() + timedelta(hours=1)
    )
    return f"https://{blob_service.account_name}.blob.core.windows.net/{AZURE_CONFIG['container']}/{latest_blob.name}?{sas_token}"

# -----------------------
# Download CSV to local path
# -----------------------
def download_csv_from_sas_url(sas_url, local_path="temp_latest.csv"):
    r = requests.get(sas_url)
    with open(local_path, 'wb') as f:
        f.write(r.content)
    return local_path

# -----------------------
# LangChain-based Insight Generator
# -----------------------
def generate_insights_using_langchain(user_query, sql_query):
    try:
        sas_url = generate_latest_blob_sas_url()
        if not sas_url:
            print("‚ùå Could not get SAS URL.")
            return

        local_csv = download_csv_from_sas_url(sas_url)
        loader = CSVLoader(file_path=local_csv)
        docs = loader.load()

        llm = ChatOpenAI(
            openai_api_key=OPENAI_CONFIG["api_key"],
            openai_api_base=OPENAI_CONFIG["endpoint"],
            openai_api_version=OPENAI_CONFIG["api_version"],
            deployment_name=OPENAI_CONFIG["deployment"]
        )

        chain = load_qa_chain(llm, chain_type="stuff")

        question = f"""Based on the result of the following SQL query:
{sql_query}

Which was generated in response to the user's question:
"{user_query}"

Please provide 5 key insights about the dataset that reflect trends, anomalies, or observations directly relevant to the query logic.
Format as:
- [Insight] ‚Äì [Why it matters]
"""
        response = chain.run(input_documents=docs, question=question)
        print("\nüîç LangChain-Powered Insights:\n", response)

    except Exception as e:
        print(f"‚ùå LangChain insights generation failed: {str(e)}")
